'''
List all hyperlinks of a website and the title.

Install bs4: pip install bs4

the URL has to have http(s)://.

###
Output

  markup_type=markup_type))
<title>Hack This Site!</title>
Hack This Site!
https://www.hackthissite.org
irc://irc.hackthissite.org:+7000/
https://www.hackthissite.org/forums
http://radio.hackthissite.org
http://hts.io/x/http://www.cafepress.com/htsstore
http://hts.io
http://hts.io/x/https://www.facebook.com/hackthissite
http://hts.io/x/https://twitter.com/#!/hackthissite
/
https://www.hackthissite.org/xCuUy2vhL87u5gW3aZkchyETkW707Ik12403lw79L7zTg706ntIyco8H5VxZqq594d18Ai4gHk22Aql5SS7y8qgFVyW3avFBz
https://www.hackthissite.org/advertise/
/user/login
/register
/user/resetpass
https://www.hackthissite.org/donate/
/missions/basic/
/missions/realistic/
/missions/application/
/missions/programming/
/missions/phonephreaking/
/missions/javascript/
/missions/forensic/
/missions/playit/extbasic/0/
/missions/playit/stego/0/

...

'''


import urllib
from bs4 import BeautifulSoup
url = raw_input("Enter the URL: ")
ht = urllib.urlopen(url)
html_page = ht.read()
b_object = BeautifulSoup(html_page, "html.parser")
print b_object.title
print b_object.title.text
for link in b_object.find_all("a"):
	print(link.get("href"))
